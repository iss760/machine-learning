{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b80fccb-fcff-473f-9c0f-e68728009bb7",
   "metadata": {},
   "source": [
    "# XGBoost (Extream Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3516145a-3409-4165-bbfd-9f7e561daffe",
   "metadata": {},
   "source": [
    "XGBoost는 앙상블(Ensemble) 기법을 구현한 대표적인 알고리즘은 Gradient Boost를 사용하며, Regression, Classification 모두에서 사용가능하다. 성능과 자원의 효율이 좋아 여러 문제에서 좋은 성과를 보여준다. 최근에는 LightGBM, Catboost 같은 보다 나은 모델이 등장하여 현업에서의 사용은 다소 줄어든 상황이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fa7c7-57ab-4159-bf13-48756184d44b",
   "metadata": {},
   "source": [
    "**XGBoost의 장점**\n",
    "- GBM 대비 빠른 수행시간\n",
    "- 병령 처리로 학습하여 속도가 빠르다.\n",
    "- 과적합 규제(Regularization)를 포함하고 있어 강한 내구성을 가진다.\n",
    "- Greedy Algorithm을 활용하여 가지치기(Pruning)하며, 이를 통해 과적합(Overfitting)에서 좀 더 자유롭다.\n",
    "- CART(Classification And Regression Tree) 앙상블 모델을 사용\n",
    "- Ealrly Stopping 기능 존재\n",
    "- 유연성이 좋아 다양한 옵션과 Customizing이 용이하다.\n",
    "- 결측치(Missing Values)를 내부적으로 처리하여 편리함을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bde3fed-dd43-433e-b356-7d4023c2fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94869c-d30f-4872-909e-20f17bd67777",
   "metadata": {},
   "source": [
    "## 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b40a2-155d-4937-bf31-393851c70d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60e352-1139-425b-b14b-b5660025d683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70048e-5df7-4814-8fed-63ad07fad332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd5dab-63d7-4227-9923-2f5104fd3277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "968fe49a-a49e-4ffd-a27f-e643214ac4fd",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b609fe6-9e34-43dd-bc38-7d6fefae3977",
   "metadata": {},
   "source": [
    "**TIP)**   \n",
    "*XGBoost의 기본 원리*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f33cc-b75c-4077-9e87-dc95405ac093",
   "metadata": {},
   "source": [
    "XGBoost는 Boosting 기법을 사용하고 Boosting 기법은 약한 분류기를 조합하여 보다 높은 정확도를 이끌어내는 기법이다. 예를 들어 어떤 학습기 $M$에 대하여 $Y$를 예측할 확률은 $Y = M_{x_{1}} + error_{(1)}$로 표현 할 수 있는데, error를 좀 더 상세하게 분류 할 수 있는 $G$모델이 있다면 $error_{(1)}$은 $error_{(1)} = G_{x_{2}} + error_{(2)}$로 표현 할 수 있다. 마찬가지로 $error_{(2)}$는 임의의 모델 $H$에 의해 $error_{(2)} = H_{x_{3}} + error_{(3)}$로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfba8d-5243-4648-b4e7-948ad7127b05",
   "metadata": {},
   "source": [
    "결론적으로, $Y$는 아래의 식으로 표현 될 수 있다.  \n",
    "$Y = M_{x_{1}} + G_{x_{2}} + H_{x_{3}} + error_{(3)}$ $(단, error_{(1)} > error_{(2)} > error_{(3)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5b2c3-5f54-407d-9aa9-b3ace699bf4c",
   "metadata": {},
   "source": [
    "이는, $M$ 하나의 모델만을 사용할 때 보다는 높은 결과를 얻을 수 있겠지만 같은 비중으로 모델 $M$, $G$, $H$를 처리하게 되면 서로 모델이 간섭하여 좋은 결과를 얻기 힘드므로, 각 모델의 가중치를 반영하고 그 결과는 다음과 같다.   \n",
    "$Y = W_{1}M_{x_{1}} + W_{2}G_{x_{2}} + W_{3}H_{x_{3}} + error_{(3)}$   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd716c-f1ac-49ea-bbe1-e1a59e60d6e8",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a15780-2804-4c5c-9fc0-1d4786bc88f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
